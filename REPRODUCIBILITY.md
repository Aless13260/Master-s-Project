# Reproducibility Guide

This document details how to reproduce the Finance Guidance Extraction pipeline results.

## 1. Environment Setup

### Python Version
- **Required**: Python 3.13 or higher
- Tested on: Python 3.13

### Virtual Environment
```bash
# Create and activate virtual environment
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## 2. Configuration

### API Keys
Copy the example environment file and add your API keys:
```bash
cp .env.example .env
```

Required keys (at least one):
| Key | Provider | Notes |
|-----|----------|-------|
| `DEEPSEEK_API_KEY` | DeepSeek | Default provider, cost-effective |
| `OPENAI_API_KEY` | OpenAI | For `--provider openai` |
| `GITHUB_MODELS_API_KEY` | GitHub | For `--provider github` |

### Contact Email
Set `CONTACT_EMAIL` in `.env` for SEC.gov compliance (they require identification in User-Agent).

### Feed Sources
`sources.yaml` defines the RSS feeds to poll. This file is version-controlled.

## 3. Data Files

### Committed (Essential for Reproducibility)
| File | Purpose |
|------|---------|
| `sources.yaml` | RSS feed definitions |
| `extractor_lib/fiscal_calendars.json` | Company fiscal year mappings |
| `evaluation/ground_truth/*.jsonl` | Labeled test data |

### Generated (Not Committed)
| Location | Contents | Regenerated By |
|----------|----------|----------------|
| `ingestion_json/` | Fetched content, caches | `rss_guidance_ingest.py`, `web_parse_trafilatura.py` |
| `extractor_lib/*.jsonl` | Extracted guidance | `LLM_extractor.py` |
| `evaluation/*.jsonl` | Evaluation outputs | `run_extraction_on_gt.py` |
| `finance_data.db` | SQLite database | `migrate_to_sqlite.py` |

## 4. Running the Pipeline

### Full Pipeline
```bash
python run_pipeline.py
```

### With Enhanced Mode (Agentic Period Normalization)
```bash
python run_pipeline.py --enhanced
```

### Step by Step
```bash
# 1. Ingest RSS feeds
python ingestion_scripts/rss_guidance_ingest.py

# 2. Parse HTML content
python ingestion_scripts/web_parse_trafilatura.py

# 3. Filter candidates
python extractor_lib/regex_filter.py

# 4. Extract guidance (LLM)
python extractor_lib/LLM_extractor.py
# or with enhanced mode:
python extractor_lib/LLM_extractor.py --enhanced

# 5. Migrate to SQLite
python migrate_to_sqlite.py
```

## 5. Determinism Notes

### LLM Outputs
- Temperature is set to `0.0` by default for deterministic outputs
- However, LLM APIs may still have slight variations between calls
- For exact reproducibility, cache/store extraction results

### Network Operations
- Retry logic handles transient failures
- Content may change over time (SEC filings are stable, press releases less so)

## 6. Evaluation

```bash
# Run extraction on ground truth
python evaluation/run_extraction_on_gt.py

# Enhanced mode
python evaluation/run_extraction_on_gt.py --enhanced

# Resume from checkpoint
python evaluation/run_extraction_on_gt.py --resume

# Compute metrics
python evaluation/evaluate_extraction.py
```

## 7. Docker (Optional)

For containerized reproducibility:

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
# Set environment variables or mount .env
CMD ["python", "run_pipeline.py"]
```

Build and run:
```bash
docker build -t finance-extractor .
docker run --env-file .env finance-extractor
```
